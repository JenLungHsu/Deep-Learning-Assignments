{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from FR import load_img_features\n",
    "\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def extract_sift_feature(image):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "\n",
    "    if descriptors is None:\n",
    "        descriptors = np.array([]).reshape(-1, 128)\n",
    "\n",
    "    # 確保特徵數量為64\n",
    "    if descriptors.shape[0] < 64:\n",
    "        descriptors = np.vstack(\n",
    "            [descriptors, np.zeros((64 - descriptors.shape[0], 128))])\n",
    "    elif descriptors.shape[0] > 64:\n",
    "        descriptors = descriptors[:64, :]\n",
    "\n",
    "    return descriptors\n",
    "\n",
    "\n",
    "def extract_orb_features(image):\n",
    "    # 创建ORB特征提取器\n",
    "    orb = cv2.ORB_create()\n",
    "\n",
    "    # 检测关键点并计算描述符\n",
    "    keypoints, descriptors = orb.detectAndCompute(image, None)\n",
    "\n",
    "    # 如果未检测到特征，则返回空特征矩阵\n",
    "    if descriptors is None:\n",
    "        descriptors = np.zeros((64, 32))  # 直接生成全零特徵矩陣\n",
    "    else:\n",
    "        # 確保特徵數量為64\n",
    "        if descriptors.shape[0] < 64:\n",
    "            descriptors = np.vstack(\n",
    "                [descriptors, np.zeros((64 - descriptors.shape[0], 32))])\n",
    "        elif descriptors.shape[0] > 64:\n",
    "            descriptors = descriptors[:64, :]\n",
    "\n",
    "    return descriptors\n",
    "\n",
    "\n",
    "def extract_brisk_features(image):\n",
    "    # 创建BRISK特征提取器\n",
    "    brisk = cv2.BRISK_create()\n",
    "\n",
    "    # 检测关键点并计算描述符\n",
    "    keypoints, descriptors = brisk.detectAndCompute(image, None)\n",
    "\n",
    "    # 如果未检测到特征，则返回空特征矩阵\n",
    "    if descriptors is None:\n",
    "        descriptors = np.zeros((64, 64))  # 直接生成全零特徵矩陣\n",
    "\n",
    "    # 確保特徵數量為64\n",
    "    if descriptors.shape[0] < 64:\n",
    "        descriptors = np.vstack(\n",
    "            [descriptors, np.zeros((64 - descriptors.shape[0], 64))])\n",
    "    elif descriptors.shape[0] > 64:\n",
    "        descriptors = descriptors[:64, :]\n",
    "\n",
    "    return descriptors\n",
    "\n",
    "\n",
    "def load_img_features(f):  # 輸入: 文件名\n",
    "\n",
    "    f = open(f)  # 打開文件, 讀取模式\n",
    "    lines = f.readlines()  # 讀取文件的所有行, 並儲存在列表中\n",
    "\n",
    "    imgs, lab, sift_f, orb_f, brisk_f, resnet_f = [], [], [], [], [], []\n",
    "\n",
    "    for i in range(len(lines)):\n",
    "        fn, label = lines[i].split(' ')  # 儲存文件路徑和標註\n",
    "        label = int(label)\n",
    "        if label in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]:\n",
    "\n",
    "            im1 = cv2.imread(fn)  # 讀取圖像文件\n",
    "            im1 = cv2.resize(im1, (256, 256))  # 將圖像調整大小為 256*256\n",
    "            im1 = cv2.cvtColor(im1, cv2.COLOR_BGR2GRAY)  # 彩色轉灰色\n",
    "\n",
    "            im_tensor = torch.Tensor(im1).unsqueeze(\n",
    "                0).unsqueeze(0)  # 添加批次和通道維度\n",
    "\n",
    "            '''===============================\n",
    "            影像處理的技巧可以放這邊，來增強影像的品質\n",
    "        \n",
    "            ==============================='''\n",
    "\n",
    "            # # 對比度增強\n",
    "            # clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "            # im1 = clahe.apply(im1)\n",
    "\n",
    "            # # 銳化\n",
    "            # kernel = np.array(\n",
    "            #     [[0, -1, 0], [-1, 5, -1], [0, -1, 0]], np.float32)\n",
    "            # im1 = cv2.filter2D(im1, -1, kernel)\n",
    "\n",
    "            # # 去噪\n",
    "            # im1 = cv2.GaussianBlur(im1, (5, 5), 0)\n",
    "\n",
    "            '''===============================\n",
    "            三個特徵提取方法: SIFT, ORB, BRISK\n",
    "\n",
    "            ==============================='''\n",
    "\n",
    "            sift_features = extract_sift_feature(im1)    # (64, 128)\n",
    "            orb_features = extract_orb_features(im1)     # (64, 32)\n",
    "            brisk_features = extract_brisk_features(im1)  # (64, 64)\n",
    "\n",
    "            '''===============================\n",
    "            基於學習的特徵提取方法: RESNET\n",
    "\n",
    "            ==============================='''\n",
    "\n",
    "            pretrained_resnet = models.resnet18(\n",
    "                pretrained='imagenet')  # 加載預訓練的ResNet模型\n",
    "            pretrained_resnet.conv1 = nn.Conv2d(\n",
    "                1, 64, kernel_size=7, stride=2, padding=3, bias=False)  # 將預訓練模型的輸入通道數修改為1\n",
    "            pretrained_resnet.fc = nn.Identity()  # 刪除最後一層全連接層\n",
    "            with torch.no_grad():\n",
    "                feature_map = pretrained_resnet(im_tensor)\n",
    "\n",
    "            '''===============================\n",
    "            二維轉為一維\n",
    "\n",
    "            ==============================='''\n",
    "\n",
    "            vec = np.reshape(im1, [-1])  # 二維的灰色圖像轉為一維\n",
    "            imgs.append(vec)  # 添加到列表中\n",
    "            lab.append(int(label))  # 添加到列表中\n",
    "\n",
    "            sift_f.append(np.reshape(sift_features, [-1]))\n",
    "            orb_f.append(np.reshape(orb_features, [-1]))\n",
    "            brisk_f.append(np.reshape(brisk_features, [-1]))\n",
    "            resnet_f.append(feature_map.squeeze().numpy())\n",
    "\n",
    "    imgs = np.asarray(imgs, np.float32)  # 列表轉為NumPy數組\n",
    "    lab = np.asarray(lab, np.int32)      # 列表轉為NumPy數組\n",
    "\n",
    "    sift_f = np.asarray(sift_f, np.float32)\n",
    "    print(\"Shape of SIFT features array:\", sift_f.shape)\n",
    "    orb_f = np.asarray(orb_f, np.float32)\n",
    "    print(\"Shape of ORB features array:\", orb_f.shape)\n",
    "    brisk_f = np.asarray(brisk_f, np.float32)\n",
    "    print(\"Shape of BRISK features array:\", brisk_f.shape)\n",
    "    resnet_f = np.array(resnet_f)\n",
    "    print(\"Shape of features array:\", resnet_f.shape)\n",
    "\n",
    "    return imgs, lab, sift_f, orb_f, brisk_f, resnet_f  # 輸出: 特徵矩陣(轉為一維)＆標註向量\n",
    "\n",
    "\n",
    "# 训练和评估模型\n",
    "def train_and_evaluate_model(X_train, X_test, y_train, y_test, model_name):\n",
    "    if model_name == \"KNN\":\n",
    "        model = KNeighborsClassifier(n_neighbors=5)\n",
    "    elif model_name == \"SVM\":\n",
    "        model = SVC(kernel='linear')\n",
    "    elif model_name == \"RandomForest\":\n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model name!\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "\n",
    "    start_time = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    end_time = time.time()\n",
    "    testing_time = end_time - start_time\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    total_time = training_time + testing_time\n",
    "\n",
    "    print(f\"{model_name} Accuracy: {accuracy}, F1 Score: {f1}\")\n",
    "    print(f\"{model_name} Training Time: {training_time} seconds\")\n",
    "    print(f\"{model_name} Testing Time: {testing_time} seconds\")\n",
    "    print(f\"{model_name} Total Time: {total_time} seconds\")\n",
    "\n",
    "    # 計算混淆矩陣\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # 繪製混淆矩陣\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('True labels')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 加载数据\n",
    "    X_train, y_train, X_train_sift, X_train_orb, X_train_brisk, X_train_resnet = load_img_features(\n",
    "        'train.txt')\n",
    "    X_test, y_test, X_test_sift, X_test_orb, X_test_brisk, X_test_resnet = load_img_features(\n",
    "        'test.txt')\n",
    "\n",
    "    # 训练和评估模型\n",
    "    models = [\"KNN\", \"SVM\", \"RandomForest\"]\n",
    "    for model_name in models:\n",
    "\n",
    "        print(f\"\\n{model_name} with sift Features:\")\n",
    "        train_and_evaluate_model(\n",
    "            X_train_sift, X_test_sift, y_train, y_test, model_name)\n",
    "\n",
    "        print(f\"\\n{model_name} with orb Features:\")\n",
    "        train_and_evaluate_model(\n",
    "            X_train_orb, X_test_orb, y_train, y_test, model_name)\n",
    "\n",
    "        print(f\"\\n{model_name} with brisk Features:\")\n",
    "        train_and_evaluate_model(\n",
    "            X_train_brisk, X_test_brisk, y_train, y_test, model_name)\n",
    "\n",
    "        print(f\"\\n{model_name} with resnet Features:\")\n",
    "        train_and_evaluate_model(\n",
    "            X_train_resnet, X_test_resnet, y_train, y_test, model_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
